<HEAD>
<TITLE></TITLE>
</HEAD>
<BODY>
<H1>PCCULL CODE FOR CULLING POINT CLOUDS OF POINTS NEAR DSMS</H1>
<HR>

<H2>INDEX</H2>
<UL>
<LI><A HREF="#grid_intro">Introduction</A>
<P>
<LI><A HREF="#grid_cull">Culling Implementation</A>
<P>
<LI><A HREF="#grid_eurocom">Installation on Eurocom</A>
<P>
<LI><A HREF="#grid_adelaide">Adelaide Map Example on the Eurocom</A>
<P>
</UL>

<H2><A NAME="grid_intro">INTRODUCTION</A></H2>

The code was originally written to cull very large point clouds where the viewer was decimating severely.
The hope was that if we culled out all the points near the corresponding DSMs that we could greatly reduce the size of the files
and thus show a much larger percentage of the points.
When we did this, we reduced the file size by about half -- not as good as we had hoped but still useful.
The resulting point clouds look significantly denser.
<P>
When the files are culled, they have to be combined with the DSM since they lose almost all their smooth areas like grass and roof tops.
The combination looks better since the point clouds add clutter to the DSM and the point clouds are denser also.
So culling is useful if the 2 datasets are combined.
<P>
The culling process takes some time, so we implemented it in a separate utility.
We made the ROI larger than default (1280x1280 rather than 128x128) and that sped up the computations greatly.
With default values it was spending most of its time rereading the elevation data for new ROIs.
<P>




<H2><A NAME="grid_cull">CULLING IMPLEMENTATION</A></H2>

One specifies all all point cloud files within a directory that match a pattern (default *.las).
The search is recursive so finds files in subdirectories.
Likewise, one finds all DSMs within a directory that match a pattern (default *.tif).
One also specifies a culling threshold; all points are culled whose elevation is closer than that threshold to the corresponding DSM elevation.
<P>
The output filenames are constructed from the input point cloud filenames by inserting "_cull".
For example the input file test.las would generate an output file test_cull.las.
<P>
The process is to read a block of point cloud data from the input file, cull it, then write it out.
Therefore, it should be able to read arbitrarily large files without memory problems.
<P>



<H2><A NAME="grid_eurocom">INSTALLATION ON EUROCOM</A></H2>

I made both 32-bit and 64-bit releases of PCCull.
I was able to put the 32-bit version in the Fusion3D bin (C:/Fusion3D/bin_r5.64) and it worked properly.
I had to put the 64-bit version in a separate bin (C:/Fusion3D/bin_PCCull_x64).
I put the executable in and added all the .dll files that were flagged as missing when I tried to start the program.
I still was getting the error message that the program failed to start.
I was able to get it to work by copying into the its bin all the .dll files from the GDAL bin.
A link to an old 32-bit GDAL is included in the path, so I guess that it is trying to pull some .dll out of that dir.
There are some new functions in the new version, so it flags those as missing but is looking for the common functions in the 32-bit dir.
<P>



<H2><A NAME="grid_adelaide">ADELAIDE MAP EXAMPLE ON THE EUROCOM</A></H2>

I ran PCCull on all the registered .las files (reg*.las) in the dir Damon is using for demos:  D:/data/Adelaide/pointclouds_large2.
This produced a group of "_cull.las" files.
Damon is only using a subset of these files, so I deleted the rest.
I made a new Project File using the culled files, D:/data/Adelaide/Adelaide_demo_jfd.s4d.
<P>



